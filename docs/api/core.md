# Core API Components

This document covers the core components of the Agentical API.

## LLMBackend

The abstract base class that defines the interface for all LLM implementations.

```python
from abc import ABC, abstractmethod
from typing import Generic, TypeVar
from mcp.types import Tool as MCPTool

Context = TypeVar("Context")

class LLMBackend(ABC, Generic[Context]):
    @abstractmethod
    async def process_query(
        self,
        query: str,
        tools: list[MCPTool],
        execute_tool: callable,
        context: Context | None = None,
    ) -> str:
        """Process a user query using the LLM and execute tool calls if needed.

        Args:
            query: The user's input query
            tools: List of available MCP tools
            execute_tool: Callback function to execute a tool
            context: Optional conversation context/history

        Returns:
            The response generated by the LLM model
        """
        pass

    @abstractmethod
    def convert_tools(self, tools: list[MCPTool]) -> list[MCPTool]:
        """Convert MCP tools to the format expected by this LLM.

        Args:
            tools: List of MCP tools to convert

        Returns:
            Tools in the format expected by this LLM implementation
        """
        pass
```

### Implementation Notes

1. **Context Management**
   - Use the `Context` type parameter for your specific context type
   - Context can be None if not needed
   - Implement proper context handling in your backend

2. **Tool Execution**
   - The `execute_tool` callback handles actual tool execution
   - Tool results should be properly integrated into responses
   - Handle tool execution errors gracefully

3. **Tool Conversion**
   - Convert MCP tools to your LLM's expected format
   - Preserve all necessary tool information
   - Handle validation and error cases

## MCPToolProvider

The main facade for integrating LLMs with MCP tools.

```python
from agentical.api import LLMBackend
from agentical.mcp.config import MCPConfigProvider
from agentical.mcp.schemas import ServerConfig

class MCPToolProvider:
    def __init__(
        self,
        llm_backend: LLMBackend,
        config_provider: MCPConfigProvider | None = None,
        server_configs: dict[str, ServerConfig] | None = None,
    ):
        """Initialize the MCP Tool Provider.

        Args:
            llm_backend: The LLM backend implementation
            config_provider: Optional configuration provider
            server_configs: Optional direct server configurations
        """
        pass

    async def initialize(self) -> None:
        """Initialize the provider with configurations."""
        pass

    def list_available_servers(self) -> list[str]:
        """List all available MCP servers.

        Returns:
            List of server names
        """
        pass

    async def mcp_connect(self, server_name: str) -> None:
        """Connect to a specific MCP server.

        Args:
            server_name: Name of the server to connect to
        """
        pass

    async def process_query(self, query: str) -> str:
        """Process a user query.

        Args:
            query: The user's input query

        Returns:
            The response from the LLM
        """
        pass

    async def cleanup(self, server_name: str | None = None) -> None:
        """Clean up resources for a specific server or all servers.

        Args:
            server_name: Optional server name to clean up
        """
        pass
```

### Key Features

- Server connection management
- Tool discovery and registration
- Query processing with LLM integration
- Resource cleanup and management
- Health monitoring

### Implementation Notes

1. **Connection Management**
   - Automatic reconnection on failures
   - Health monitoring with heartbeats
   - Proper resource cleanup

2. **Tool Registry**
   - Efficient tool lookup and dispatch
   - Server-specific tool namespacing
   - Tool validation and conversion

3. **Resource Management**
   - Uses AsyncExitStack for cleanup
   - Proper handling of server sessions
   - Guaranteed resource cleanup

## ChatClient

Interactive chat client for the MCP Tool Provider.

```python
from agentical.api import LLMBackend
from agentical.mcp import MCPToolProvider

async def run_demo(llm_backend: LLMBackend):
    """Run an interactive demo session.

    Args:
        llm_backend: The LLM backend to use
    """
    pass

async def chat_loop(provider: MCPToolProvider):
    """Run an interactive chat session.

    Args:
        provider: The configured MCP Tool Provider
    """
    pass

async def interactive_server_selection(provider: MCPToolProvider) -> str | None:
    """Prompt user to select an MCP server.

    Args:
        provider: The MCP Tool Provider

    Returns:
        Selected server name or None for all servers
    """
    pass
```

### Key Features

1. **Interactive Mode**
   - User-friendly command-line interface
   - Server selection prompts
   - Query/response loop
   - Clean exit handling

2. **Error Handling**
   - Query processing error capture
   - User input validation
   - Session statistics tracking

3. **Logging**
   - Comprehensive session logging
   - Query timing information
   - Error tracking and reporting